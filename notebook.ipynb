{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 9,500 miles (15,300 kilometers). My name is Assistant.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.callbacks import FinalStreamingStdOutCallbackHandler\n",
    "\n",
    "chat  = ChatOpenAI(\n",
    "  temperature=0.1,\n",
    "  streaming=True, \n",
    "  callbacks=[FinalStreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "template = PromptTemplate.from_template('What is the distance between {country_a} and {country_b} Also, what is your name?')\n",
    "prompt = template.format(country_a='Mexico', country_b='Thailand')\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Γεια σας! Το όνομά μου είναι Σωκράτης. Η απόσταση μεταξύ του Μεξικού και της Ταϊλάνδης είναι περίπου 16.000 χιλιόμετρα.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a geography export. And you only reply in {language}.\"), \n",
    "  (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "  (\"human\", \"What is the distance between {country_a} and {country_b} Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "  language='Greek',\n",
    "  name=\"Socrates\",\n",
    "  country_a='Mexico',\n",
    "  country_b='Thailand'\n",
    ")\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "from langchain.schema import BaseOutputParser \n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "  def parse(self, test):\n",
    "    items = test.strip().split(',')\n",
    "    return list(map(str.strip, items))\n",
    "    \n",
    "\n",
    "# p = CommaOutputParser()\n",
    "# p.parse(\"Hello, how, are, you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mercury', 'venus', 'earth', 'mars', 'jupiter', 'saturn', 'uranus', 'neptune']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase . Do NOT reply with anything else\"), \n",
    "  (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "  max_items=10,\n",
    "  question=\"What are the planets?\"\n",
    ")\n",
    "result = chat.predict_messages(prompt)\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bulbasaur',\n",
       " 'ivysaur',\n",
       " 'venusaur',\n",
       " 'charmander',\n",
       " 'charmeleon',\n",
       " 'charizard',\n",
       " 'squirtle',\n",
       " 'wartortle',\n",
       " 'blastoise',\n",
       " 'pikachu']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | chat | CommaOutputParser()  # Chain! \n",
    "chain.invoke({\n",
    "  \"max_items\": 10,\n",
    "  \"question\": \"What are the pokemons?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"To make a vegetarian version of Chicken Tikka Masala, we can substitute the chicken with a plant-based alternative such as tofu or paneer. Here's how you can adapt the recipe:\\n\\nIngredients:\\n- 1 lb firm tofu or paneer, cut into bite-sized pieces\\n- 1 cup plain yogurt (you can use dairy-free yogurt for a vegan version)\\n- 2 tbsp lemon juice\\n- 2 tbsp vegetable oil\\n- 1 large onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1-inch piece of ginger, grated\\n- 1 can (14 oz) diced tomatoes\\n- 2 tbsp tomato paste\\n- 1 tbsp garam masala\\n- 1 tsp ground cumin\\n- 1 tsp ground coriander\\n- 1 tsp turmeric\\n- 1/2 tsp cayenne pepper (adjust to taste)\\n- Salt and pepper to taste\\n- 1/2 cup coconut cream (or any other dairy-free cream alternative)\\n- Fresh cilantro, chopped (for garnish)\\n\\nInstructions:\\n1. Follow the same marinating process as the original recipe, but instead of chicken, marinate the tofu or paneer in the yogurt and spice mixture. Let it marinate for at least 1 hour in the refrigerator.\\n\\n2. Bake the marinated tofu or paneer in the preheated oven at 400°F (200°C) for about 20-25 minutes or until it is slightly browned.\\n\\n3. In a skillet, follow the same steps for sautéing the onion, garlic, and ginger. Add the diced tomatoes, tomato paste, and spices. Simmer for 10-15 minutes.\\n\\n4. Add the baked tofu or paneer to the skillet and stir to coat with the sauce. Pour in the coconut cream and simmer for an additional 5 minutes.\\n\\n5. Adjust the seasoning with salt, pepper, and cayenne pepper as needed.\\n\\n6. Serve the Vegetarian Tikka Masala over rice or with naan bread. Garnish with chopped cilantro before serving.\\n\\nEnjoy your flavorful Vegetarian Tikka Masala!\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat  = ChatOpenAI(\n",
    "  temperature=0.1,\n",
    "  streaming=True, \n",
    "  callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a world-class international chef. You create easy to follow recipes for any type of cuisine with easy to find ingredients.\"),\n",
    "  (\"human\", \"I want to cook {cuisine} food.\")\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat \n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\"),\n",
    "  (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain\n",
    "final_chain.invoke({\"cuisine\": \"indian\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
